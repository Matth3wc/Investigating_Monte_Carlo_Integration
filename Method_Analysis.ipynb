{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pip install nbimporter\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''pip install nbimporter\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "\n",
    "#==============================Dependencies================================\n",
    "\n",
    "#libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm, truncnorm\n",
    "from numpy.random import Generator, MT19937\n",
    "import time\n",
    "\n",
    "#Initializing the random number generator\n",
    "seed = int(time.time()) \n",
    "bitgen = MT19937(seed)\n",
    "rng = Generator(bitgen)  # reproducible generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid_mcmc_KDE import metropolis_python, silverman_bandwidth, adaptive_kde, hybrid_importance_sampling  \n",
    "\n",
    "from Importance_Int import importance_integration, target_pdf\n",
    "\n",
    "from Uniform_MC import uniform_mc_integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integration_over_N(integration_type, N_values, f, rng, m_chain):\n",
    "    \"\"\"\n",
    "    Compute integration estimates, variances, and standard errors for a range of N values.\n",
    "    \n",
    "    Parameters:\n",
    "        integration_type (str): The type of integration to perform. \n",
    "            Options are \"uniform\", \"importance\", or \"hybrid\".\n",
    "        N_values (array-like): An array of sample sizes to iterate over.\n",
    "        f (callable): The integrand function.\n",
    "        rng (np.random.Generator): Random number generator.\n",
    "        kwargs: Additional keyword arguments required by a given integration method.\n",
    "            For the \"uniform\" method, provide:\n",
    "                a (float): lower integration limit\n",
    "                b (float): upper integration limit\n",
    "            For the \"hybrid\" method, you may provide:\n",
    "                initial_point (float): starting point for the metropolis chain (default: rng.uniform(-1,1))\n",
    "                proposal_width (float): proposal step width (default: 4)\n",
    "                burn_in (int): number of burn-in iterations (default: 200)\n",
    "                thinning (int): thinning factor (default: 1)\n",
    "                kde_alpha (float): alpha parameter for adaptive_kde (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        estimates (np.ndarray): Array of integration estimates for each N.\n",
    "        variances (np.ndarray): Array of variances for each N.\n",
    "        standard_errors (np.ndarray): Array of standard errors for each N.\n",
    "    \"\"\"\n",
    "    estimates = []\n",
    "    variances = []\n",
    "    standard_errors = []\n",
    "\n",
    "    for N in N_values:\n",
    "        if integration_type == \"uniform\":\n",
    "            a = kwargs.get('a')\n",
    "            b = kwargs.get('b')\n",
    "            if a is None or b is None:\n",
    "                raise ValueError(\"For uniform integration, 'a' and 'b' must be provided.\")\n",
    "            estimate, var, se = uniform_mc_integrate(f, a, b, N, rng)\n",
    "            \n",
    "        elif integration_type == \"importance\":\n",
    "            estimate, var, se = importance_integration(f, N, rng, m_chain)\n",
    "            \n",
    "        elif integration_type == \"hybrid\":\n",
    "            # Optional parameters for hybrid method\n",
    "            initial_point = kwargs.get('initial_point', rng.uniform(-1, 1))\n",
    "            proposal_width = kwargs.get('proposal_width', 4)\n",
    "            burn_in = kwargs.get('burn_in', 200)\n",
    "            thinning = kwargs.get('thinning', 1)\n",
    "            kde_alpha = kwargs.get('kde_alpha', 0.5)\n",
    "            \n",
    "            m_chain = metropolis_python(f, N, initial_point, proposal_width, burn_in, thinning)\n",
    "            h_fixed = silverman_bandwidth(m_chain)\n",
    "            kde = adaptive_kde(m_chain, h_fixed, alpha=kde_alpha)\n",
    "            estimate, var, se = hybrid_importance_sampling(f, m_chain, kde)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown integration type: {integration_type}\")\n",
    "        \n",
    "        estimates.append(estimate)\n",
    "        variances.append(var)\n",
    "        standard_errors.append(se)\n",
    "        \n",
    "    return np.array(estimates), np.array(variances), np.array(standard_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m kde_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mperform_integrations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mxo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstepsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mburn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkde_alpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m estimates_u, variances_u, standard_errors_u, estimates_i, variances_i, standard_errors_i, estimates_h, variances_h, standard_errors_h \u001b[38;5;241m=\u001b[39m results\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mperform_integrations\u001b[0;34m(N_values, f, rng, xo, stepsize, burn_in, thinning, kde_alpha)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mPerform uniform, importance, and hybrid integrations over a range of N values.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    tuple: Estimates, variances, and standard errors for uniform, importance, and hybrid methods.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m m_chain \u001b[38;5;241m=\u001b[39m metropolis_python(f, N_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], rng\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Generate m_chain for importance integration\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m estimates_i, variances_i, standard_errors_i \u001b[38;5;241m=\u001b[39m \u001b[43mintegration_over_N\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_chain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m estimates_h, variances_h, standard_errors_h \u001b[38;5;241m=\u001b[39m integration_over_N(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m'\u001b[39m, N_values, f, rng,\n\u001b[1;32m     24\u001b[0m     initial_point\u001b[38;5;241m=\u001b[39mxo,\n\u001b[1;32m     25\u001b[0m     proposal_width\u001b[38;5;241m=\u001b[39mstepsize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     kde_alpha\u001b[38;5;241m=\u001b[39mkde_alpha\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimates_u, variances_u, standard_errors_u, estimates_i, variances_i, standard_errors_i, estimates_h, variances_h, standard_errors_h\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mintegration_over_N\u001b[0;34m(integration_type, N_values, f, rng, m_chain)\u001b[0m\n\u001b[1;32m     37\u001b[0m     estimate, var, se \u001b[38;5;241m=\u001b[39m uniform_mc_integrate(f, a, b, N, rng)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m integration_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     estimate, var, se \u001b[38;5;241m=\u001b[39m importance_integration(f, N, rng, m_chain)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m integration_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhybrid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Optional parameters for hybrid method\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     initial_point \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_point\u001b[39m\u001b[38;5;124m'\u001b[39m, rng\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "# Define a range of N values\n",
    "def perform_integrations(N_values, f, rng,xo, stepsize, burn_in, thinning, kde_alpha):\n",
    "    \"\"\"\n",
    "    Perform uniform, importance, and hybrid integrations over a range of N values.\n",
    "\n",
    "    Parameters:\n",
    "        N_values (numpy.ndarray): Array of sample sizes.\n",
    "        f (callable): The integrand function.\n",
    "        rng (numpy.random.Generator): Random number generator.\n",
    "        a (float): Lower integration limit for uniform integration.\n",
    "        b (float): Upper integration limit for uniform integration.\n",
    "        xo (float): Initial point for the hybrid method.\n",
    "        stepsize (float): Proposal step width for the hybrid method.\n",
    "        burn_in (int): Number of burn-in iterations for the hybrid method.\n",
    "        thinning (int): Thinning factor for the hybrid method.\n",
    "        kde_alpha (float): Alpha parameter for adaptive KDE in the hybrid method.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Estimates, variances, and standard errors for uniform, importance, and hybrid methods.\n",
    "    \"\"\"\n",
    "    m_chain = metropolis_python(f, N_values[-1], rng.uniform(-1, 1), 4, 0, 1)  # Generate m_chain for importance integration\n",
    "    estimates_i, variances_i, standard_errors_i = integration_over_N('importance', N_values, f, rng, m_chain)\n",
    "    estimates_h, variances_h, standard_errors_h = integration_over_N('hybrid', N_values, f, rng,\n",
    "        initial_point=xo,\n",
    "        proposal_width=stepsize,\n",
    "        burn_in=burn_in,\n",
    "        thinning=thinning,\n",
    "        kde_alpha=kde_alpha\n",
    "    )\n",
    "    return estimates_u, variances_u, standard_errors_u, estimates_i, variances_i, standard_errors_i, estimates_h, variances_h, standard_errors_h\n",
    "\n",
    "N_values = np.logspace(1, 4, num=50, dtype=int)#[5_000, 6000, 7000, 8000, 9000, 10_000, 12500, 15000, 20_000, 25000, 30000, 35000, 40_000]\n",
    "def f(x):\n",
    "    return np.exp(-x**2)\n",
    "\n",
    "xo = rng.uniform(-2, 2)\n",
    "stepsize = 3\n",
    "burn_in = 0\n",
    "thinning = 1\n",
    "kde_alpha = 0.5\n",
    "\n",
    "# Call the function\n",
    "results = perform_integrations(N_values, f, rng,  xo, stepsize, burn_in, thinning, kde_alpha)\n",
    "estimates_u, variances_u, standard_errors_u, estimates_i, variances_i, standard_errors_i, estimates_h, variances_h, standard_errors_h = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     88\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     91\u001b[0m plot_integration_results(\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mN_values\u001b[49m, estimates_u, standard_errors_u, estimates_i, standard_errors_i, \n\u001b[1;32m     93\u001b[0m     estimates_h, standard_errors_h, variances_u, variances_i, variances_h, \n\u001b[1;32m     94\u001b[0m     reference_line, analytical_result, function_description\n\u001b[1;32m     95\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N_values' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_integration_results(N_values, estimates_u, standard_errors_u, estimates_i, standard_errors_i, \n",
    "                              estimates_h, standard_errors_h, variances_u, variances_i, variances_h, \n",
    "                              reference_line, analytical_result, function_description):\n",
    "    \"\"\"\n",
    "    Plot integration results including estimates, variances, and standard errors.\n",
    "\n",
    "    Parameters:\n",
    "        N_values (numpy.ndarray): Array of sample sizes.\n",
    "        estimates_u (numpy.ndarray): Uniform MC estimates.\n",
    "        standard_errors_u (numpy.ndarray): Standard errors for Uniform MC.\n",
    "        estimates_i (numpy.ndarray): Importance Sampling estimates.\n",
    "        standard_errors_i (numpy.ndarray): Standard errors for Importance Sampling.\n",
    "        estimates_h (numpy.ndarray): Hybrid Sampling estimates.\n",
    "        standard_errors_h (numpy.ndarray): Standard errors for Hybrid Sampling.\n",
    "        variances_u (numpy.ndarray): Variances for Uniform MC.\n",
    "        variances_i (numpy.ndarray): Variances for Importance Sampling.\n",
    "        variances_h (numpy.ndarray): Variances for Hybrid Sampling.\n",
    "        reference_line (numpy.ndarray): Reference line values (1/sqrt(N)).\n",
    "        analytical_result (float): Analytical result of the integral.\n",
    "        function_description (str): Description of the function being integrated.\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'axes.titlesize': 16, 'axes.titleweight': 'bold', 'axes.titlepad': -20})\n",
    "\n",
    "    # Plot estimates with error bars\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.errorbar(N_values, estimates_u, yerr=standard_errors_u, label='Uniform MC', \n",
    "                 fmt='s-', markersize=1, markerfacecolor='black', markeredgecolor='black', \n",
    "                 ecolor='black', capsize=3)\n",
    "    plt.errorbar(N_values, estimates_i, yerr=standard_errors_i, label='Importance Sampling', \n",
    "                 fmt='s-', markersize=1, markerfacecolor='black', markeredgecolor='black', \n",
    "                 ecolor='black', capsize=3)\n",
    "    plt.errorbar(N_values, estimates_h, yerr=standard_errors_h, label='Hybrid Sampling', \n",
    "                 fmt='s-', markersize=1, markerfacecolor='black', markeredgecolor='black', \n",
    "                 ecolor='black', capsize=3)\n",
    "\n",
    "    plt.axhline(y=analytical_result, color='red', linestyle='--', label='Analytical Result', alpha=0.2)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Number of Samples (N)')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Importance Integration Method vs N:  {function_description}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot estimates with 95% confidence intervals\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.errorbar(N_values, estimates_i, yerr=1.96 * standard_errors_i, label='Importance Sampling', \n",
    "                 fmt='s-', markersize=1)\n",
    "    plt.errorbar(N_values, estimates_h, yerr=1.96 * standard_errors_h, label='Hybrid Sampling', \n",
    "                 fmt='s-', markersize=1)\n",
    "\n",
    "    plt.axhline(y=analytical_result, color='red', linestyle='--', label='Analytical Result', alpha=0.2)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Number of Samples (N)')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Importance Integration Method vs N:   {function_description}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot variances\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(N_values, variances_u, label='Variance', marker='x')\n",
    "    plt.plot(N_values, variances_i, label='Variance IS', marker='x')\n",
    "    plt.plot(N_values, variances_h, label='Variance Hybrid', marker='x')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Number of Samples (N)')\n",
    "    plt.ylabel('Variance')\n",
    "    plt.title(f'Variance vs N:   {function_description}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot standard errors\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(N_values, standard_errors_u, label='STDERR')\n",
    "    plt.plot(N_values, standard_errors_i, label='STDERR IS')\n",
    "    plt.plot(N_values, standard_errors_h, label='STDERR Hybrid')\n",
    "    plt.plot(N_values, reference_line, label='1/sqrt(N)', linestyle='--', color='orange')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Number of Samples (N)')\n",
    "    plt.ylabel('Standard Errors')\n",
    "    plt.title(f'Standard Errors vs N with Reference Line:    {function_description}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_integration_results(\n",
    "    N_values, estimates_u, standard_errors_u, estimates_i, standard_errors_i, \n",
    "    estimates_h, standard_errors_h, variances_u, variances_i, variances_h, \n",
    "    reference_line, analytical_result, function_description\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
