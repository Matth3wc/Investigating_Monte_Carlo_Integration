{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyrbid Importance Sampling with Markov Chains For Monte Crlo Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#==============================Dependencies================================\n",
    "\n",
    "#libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm, truncnorm\n",
    "from numpy.random import Generator, MT19937\n",
    "import time\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "#Initializing the random number generator\n",
    "seed = int(time.time()) \n",
    "bitgen = MT19937(seed)\n",
    "rng = Generator(bitgen)  # reproducible generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian proposal\n",
    "def gaussian_proposal(x, step_size):\n",
    "    return x + step_size * np.random.normal()\n",
    "\n",
    "# Cauchy distribution: p(x) = 1 / (Ï€ * (1 + x^2))\n",
    "def cauchy_distribution(x, step_size):\n",
    "    return (step_size) * 1 / (pi * (1 + x**2))\n",
    "\n",
    "# Uniform sampling proposal\n",
    "def uniform_proposal(x, step_size):\n",
    "    return x + step_size * rng.uniform(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================Metropolis-Hastings Algorithm (Python)========================\n",
    "def metropolis_python(f, N, x0, step_size, burnin, thinning, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    total_steps = N * thinning + burnin\n",
    "    samples = []\n",
    "    x = x0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(total_steps):\n",
    "        x_cand = gaussian_proposal(x, step_size)\n",
    "        alpha = min(1.0, f(x_cand) / f(x))\n",
    "        if rng.uniform() < alpha:\n",
    "            x = x_cand\n",
    "            count += 1\n",
    "        if i >= burnin and (i - burnin) % thinning == 0:\n",
    "            samples.append(x)\n",
    "    acceptance_rate = count / total_steps\n",
    "    \n",
    "    print(f\"Acceptance rate: {acceptance_rate:.2f}\")\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cython in /Users/mattthew/Library/Python/3.9/lib/python/site-packages (3.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Importing Cython for performance optimization\n",
    "!/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install cython\n",
    "\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "#=======================Metropolis-Hastings Algorithm (Cython)========================\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.stdlib cimport rand, RAND_MAX\n",
    "from libc.math cimport fmin\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "\n",
    "def metropolis_cython(int N, double x0, double step_size, int burnin, int thinning):\n",
    "    cdef int total_steps = N * thinning + burnin\n",
    "    cdef np.ndarray[np.double_t, ndim=1] samples = np.empty(N, dtype=np.double)\n",
    "    cdef double x = x0\n",
    "    cdef int i, count = 0\n",
    "    cdef double x_cand, alpha, u\n",
    "\n",
    "    for i in range(total_steps):\n",
    "        x_cand = x + step_size * np.random.normal()\n",
    "        alpha = fmin(1.0, (1.0 / (1.0 + x_cand * x_cand)) / (1.0 / (1.0 + x * x)))\n",
    "        u = rand() / <double>RAND_MAX\n",
    "        if u < alpha:\n",
    "            x = x_cand\n",
    "        if i >= burnin and (i - burnin) % thinning == 0:\n",
    "            samples[count] = x\n",
    "            count += 1\n",
    "    samples.sort()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate: 0.45\n",
      "Metropolis-Hastings Python implementation loaded. [0.21981245 0.48764505 3.24302536 ... 0.35789229 1.67326177 1.67326177]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 1 / (1 + x**2)  # Cauchy distribution\n",
    "\n",
    "print(\"Metropolis-Hastings Python implementation loaded.\", metropolis_python(f, 10000, rng.uniform(-1, 1), 4, 200, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function average chain maker needs work, but its goal to to averae many different markov chains in the aim of lower the variane of the KDe pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================Kernel Density Estimation (KDE) Functions========================\n",
    "\n",
    "# Fixed-bandwidth KDE\n",
    "def pilot_kde(samples, bandwidth): #fixed KDE mthod\n",
    "    \"\"\"Fixed-bandwidth KDE using Gaussian kernel.\"\"\"\n",
    "    def kde_eval(x_eval):\n",
    "        x_eval = np.atleast_1d(x_eval)\n",
    "        n = len(samples)\n",
    "        coeff = 1 / (n * bandwidth * np.sqrt(2 * np.pi))\n",
    "        diffs = (x_eval[:, None] - samples[None, :]) / bandwidth\n",
    "        return coeff * np.sum(np.exp(-0.5 * diffs**2), axis=1)\n",
    "    return kde_eval\n",
    "\n",
    "def silverman_bandwidth(samples):\n",
    "    n = len(samples)\n",
    "    std = np.std(samples, ddof=1)\n",
    "    return 1.06 * std * n ** (-1/5)\n",
    "\n",
    "# Adaptive-bandwidth KDE\n",
    "def adaptive_kde(samples, h_fixed, alpha=0.5): # Adative KDE method\n",
    "    \"\"\"\n",
    "    Adaptive KDE using Abramson's square-root law.\n",
    "    samples : 1D array of data points\n",
    "    h_fixed : base bandwidth for pilot KDE\n",
    "    alpha   : sensitivity parameter (default 0.5)\n",
    "    \"\"\"\n",
    "    n = len(samples)\n",
    "\n",
    "    # Step 1: pilot density estimate\n",
    "    pilot = pilot_kde(samples, h_fixed)\n",
    "    f_i = pilot(samples)\n",
    "\n",
    "    # Step 2: compute geometric mean of pilot estimates\n",
    "    g = np.exp(np.mean(np.log(f_i)))\n",
    "\n",
    "    # Step 3: compute local bandwidth factors\n",
    "    lambda_i = (f_i / g)**(-alpha)\n",
    "    h_i = h_fixed * lambda_i\n",
    "\n",
    "    # Step 4: adaptive KDE function\n",
    "    def kde_adaptive(x_eval):\n",
    "        x_eval = np.atleast_1d(x_eval)\n",
    "        coeffs = 1 / (np.sqrt(2 * np.pi) * h_i)\n",
    "        diffs = (x_eval[:, None] - samples[None, :]) / h_i\n",
    "        result = np.sum(coeffs * np.exp(-0.5 * diffs**2), axis=1) / n\n",
    "        return result\n",
    "\n",
    "    return kde_adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_importance_sampling(f, m_chain, kde_pdf):\n",
    "    \"\"\"\n",
    "    Estimate the integral of f using importance sampling from KDE-estimated proposal.\n",
    "\n",
    "    Returns:\n",
    "        estimate: Monte Carlo estimate of the integral\n",
    "        stderr: Standard error of the estimate (not just std of weights)\n",
    "    \"\"\"\n",
    "    weights = f(m_chain) / kde_pdf(m_chain)\n",
    "    estimate = np.mean(weights)\n",
    "    \n",
    "    \n",
    "    n = len(weights)\n",
    "    variance = np.var(weights, ddof=1) / n    # variance of the estimator\n",
    "    stderr = np.sqrt(variance) / np.sqrt(n)               # standard error of the estimator\n",
    "\n",
    "    return estimate, stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate: 0.45\n",
      "Hybrid Importance Sampling Estimate:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(3.153566180528676), np.float64(4.2996963122588064e-05))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=10000\n",
    "m_chain = metropolis_python(f, N, rng.uniform(-1, 1), 4, 200, 1)\n",
    "h_fixed = silverman_bandwidth(m_chain)\n",
    "kde = adaptive_kde(m_chain, h_fixed, alpha=0.5)\n",
    "\n",
    "print(\"Hybrid Importance Sampling Estimate:\"),\n",
    "hybrid_importance_sampling(f, m_chain, kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate: 0.42\n",
      "Acceptance rate: 0.47\n",
      "Acceptance rate: 0.49\n",
      "Acceptance rate: 0.49\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.49\n",
      "Acceptance rate: 0.49\n",
      "Acceptance rate: 0.46\n",
      "Acceptance rate: 0.47\n",
      "Acceptance rate: 0.46\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.44\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.47\n",
      "Acceptance rate: 0.44\n",
      "Acceptance rate: 0.46\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.46\n",
      "Acceptance rate: 0.46\n",
      "Acceptance rate: 0.44\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.49\n",
      "Acceptance rate: 0.51\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.48\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.47\n",
      "Acceptance rate: 0.47\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.55\n",
      "Acceptance rate: 0.50\n",
      "Acceptance rate: 0.46\n",
      "Acceptance rate: 0.49\n",
      "Acceptance rate: 0.45\n",
      "Acceptance rate: 0.46\n",
      "Acceptance rate: 0.47\n",
      "Acceptance rate: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Define the range of N values\n",
    "N_values = np.arange(500, 30001, 500)\n",
    "estimates = []\n",
    "errors = []\n",
    "\n",
    "# Compute the hybrid importance sampling estimate for each N\n",
    "for N in N_values:\n",
    "    m_chain = metropolis_python(f, N, rng.uniform(-1, 1), 4, 200, 1)\n",
    "    h_fixed = silverman_bandwidth(m_chain)\n",
    "    kde = adaptive_kde(m_chain, h_fixed, alpha=0.5)\n",
    "    estimate, stderr = hybrid_importance_sampling(f, m_chain, kde)\n",
    "    estimates.append(estimate)\n",
    "    errors.append(stderr)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(N_values, estimates, yerr=errors, fmt='o', label='Estimate with Error Bars')\n",
    "plt.xlabel('N (Number of Samples)')\n",
    "plt.ylabel('Hybrid Importance Sampling Estimate')\n",
    "plt.title('Hybrid Importance Sampling vs N')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def avg_chain_maker(K, chain_maker):\\n    \"\"\"\\n    Call `chain_maker()` K times, average the resulting chains element-wise.\\n\\n    Parameters:\\n        K (int): Number of chains to generate.\\n        chain_maker (function): A function that returns a 1D NumPy array.\\n\\n    Returns:\\n        avg_chain (np.ndarray): 1D array of the average of K chains.\\n    \"\"\"\\n    chains = [chain_maker() for _ in range(K)]       # List of K arrays\\n    stacked = np.stack(chains)                       # Shape: (K, N)\\n    avg_chain = np.mean(stacked, axis=0)             # Shape: (N,)\\n    return avg_chain'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def avg_chain_maker(K, chain_maker):\n",
    "    \"\"\"\n",
    "    Call `chain_maker()` K times, average the resulting chains element-wise.\n",
    "\n",
    "    Parameters:\n",
    "        K (int): Number of chains to generate.\n",
    "        chain_maker (function): A function that returns a 1D NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        avg_chain (np.ndarray): 1D array of the average of K chains.\n",
    "    \"\"\"\n",
    "    chains = [chain_maker() for _ in range(K)]       # List of K arrays\n",
    "    stacked = np.stack(chains)                       # Shape: (K, N)\n",
    "    avg_chain = np.mean(stacked, axis=0)             # Shape: (N,)\n",
    "    return avg_chain'''\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
